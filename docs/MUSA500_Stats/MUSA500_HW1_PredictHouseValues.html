<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Ling Chen, Hang Zhao, Jiahang Li">
<meta name="dcterms.date" content="2023-10-16">

<title>Hang Zhao Personal Website - MUSA500 Homework 1: Using OLS Regression to Predict Median House Values in Philadelphia</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
</head><body class="nav-sidebar docked">\usepackage[utf8]{inputenc}

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">




<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../MUSA500_Stats/MUSA500_HW1_PredictHouseValues.html">MUSA500_Stats</a></li><li class="breadcrumb-item"><a href="../MUSA500_Stats/MUSA500_HW1_PredictHouseValues.html">MUSA500 Homework 1: Using OLS Regression to Predict Median House Values in Philadelphia</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-center sidebar-header">
      <a href="../index.html" class="sidebar-logo-link">
      <img src="../images/Penn_Logo.jpg" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
      <div class="sidebar-tools-main tools-wide">
    <a href="../hangzh@sas.upenn.edu" rel="" title="Email" class="quarto-navigation-tool px-1" aria-label="Email"><i class="bi bi-globe"></i></a>
    <a href="https://github.com/Cyanhang" rel="" title="Hang's GitHub" class="quarto-navigation-tool px-1" aria-label="Hang's GitHub"><i class="bi bi-github"></i></a>
    <a href="../www.linkedin.com/in/hang-zhao-62060a1a9" rel="" title="Hang's Linkedin" class="quarto-navigation-tool px-1" aria-label="Hang's Linkedin"><i class="bi bi-linkedin"></i></a>
</div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About me</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../analysis/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Analysis</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../analysis/1-python-code-blocks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Python code blocks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../analysis/2-static-images.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Showing static visualizations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../analysis/3-altair-hvplot.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Altair and Hvplot Charts</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../analysis/4-folium.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Interactive Maps with Folium</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">MUSA500_Stats</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../MUSA500_Stats/MUSA500_HW1_PredictHouseValues.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">MUSA500 Homework 1: Using OLS Regression to Predict Median House Values in Philadelphia</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><strong>Introduction</strong></a></li>
  <li><a href="#methods" id="toc-methods" class="nav-link" data-scroll-target="#methods"><strong>Methods</strong></a>
  <ul class="collapse">
  <li><a href="#data-cleaning" id="toc-data-cleaning" class="nav-link" data-scroll-target="#data-cleaning"><strong>Data Cleaning</strong></a></li>
  <li><a href="#exploratory-analysis" id="toc-exploratory-analysis" class="nav-link" data-scroll-target="#exploratory-analysis"><strong>Exploratory Analysis</strong></a></li>
  <li><a href="#multiple-regression-analysis" id="toc-multiple-regression-analysis" class="nav-link" data-scroll-target="#multiple-regression-analysis"><strong>Multiple Regression Analysis</strong></a></li>
  <li><a href="#additional-analyses" id="toc-additional-analyses" class="nav-link" data-scroll-target="#additional-analyses"><strong>Additional Analyses</strong></a></li>
  <li><a href="#software" id="toc-software" class="nav-link" data-scroll-target="#software"><strong>Software</strong></a></li>
  </ul></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results"><strong>Results</strong></a>
  <ul class="collapse">
  <li><a href="#exploratory-results" id="toc-exploratory-results" class="nav-link" data-scroll-target="#exploratory-results"><strong>Exploratory Results</strong></a>
  <ul class="collapse">
  <li><a href="#summary-statistics" id="toc-summary-statistics" class="nav-link" data-scroll-target="#summary-statistics">Summary Statistics</a></li>
  <li><a href="#histograms-and-log-transformation" id="toc-histograms-and-log-transformation" class="nav-link" data-scroll-target="#histograms-and-log-transformation">Histograms and Log Transformation</a></li>
  <li><a href="#choropleth-maps" id="toc-choropleth-maps" class="nav-link" data-scroll-target="#choropleth-maps">Choropleth maps</a></li>
  <li><a href="#correlation-matrix" id="toc-correlation-matrix" class="nav-link" data-scroll-target="#correlation-matrix">Correlation Matrix</a></li>
  </ul></li>
  <li><a href="#regression-results" id="toc-regression-results" class="nav-link" data-scroll-target="#regression-results"><strong>Regression Results</strong></a></li>
  <li><a href="#regression-assumption-checks" id="toc-regression-assumption-checks" class="nav-link" data-scroll-target="#regression-assumption-checks"><strong>Regression Assumption Checks</strong></a>
  <ul class="collapse">
  <li><a href="#model-assumptions-linearity" id="toc-model-assumptions-linearity" class="nav-link" data-scroll-target="#model-assumptions-linearity">Model Assumptions: Linearity</a></li>
  <li><a href="#normality-of-residuals" id="toc-normality-of-residuals" class="nav-link" data-scroll-target="#normality-of-residuals">Normality of residuals</a></li>
  <li><a href="#additional-checks-homoscedasticity" id="toc-additional-checks-homoscedasticity" class="nav-link" data-scroll-target="#additional-checks-homoscedasticity">Additional Checks: Homoscedasticity</a></li>
  <li><a href="#spatial-autocorrelation" id="toc-spatial-autocorrelation" class="nav-link" data-scroll-target="#spatial-autocorrelation">Spatial Autocorrelation</a></li>
  <li><a href="#standardized-regression-residuals-map" id="toc-standardized-regression-residuals-map" class="nav-link" data-scroll-target="#standardized-regression-residuals-map">Standardized regression residuals map</a></li>
  </ul></li>
  <li><a href="#additional-models" id="toc-additional-models" class="nav-link" data-scroll-target="#additional-models"><strong>Additional Models</strong></a>
  <ul class="collapse">
  <li><a href="#using-stepwise-regression-and-determine-the-best-model" id="toc-using-stepwise-regression-and-determine-the-best-model" class="nav-link" data-scroll-target="#using-stepwise-regression-and-determine-the-best-model">using stepwise regression and determine the best model</a></li>
  <li><a href="#k-fold-model" id="toc-k-fold-model" class="nav-link" data-scroll-target="#k-fold-model">K-fold model</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#discussion-and-limitations" id="toc-discussion-and-limitations" class="nav-link" data-scroll-target="#discussion-and-limitations"><strong>Discussion and Limitations</strong></a>
  <ul class="collapse">
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  <li><a href="#model-quality" id="toc-model-quality" class="nav-link" data-scroll-target="#model-quality">Model Quality</a></li>
  <li><a href="#limitations" id="toc-limitations" class="nav-link" data-scroll-target="#limitations">Limitations</a></li>
  <li><a href="#ridge-and-lasso-regression" id="toc-ridge-and-lasso-regression" class="nav-link" data-scroll-target="#ridge-and-lasso-regression">Ridge and LASSO Regression</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><strong>References</strong></a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/Cyanhang/Hang/blob/main/MUSA500_Stats/MUSA500_HW1_PredictHouseValues.Rmd" class="toc-action">View source</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">MUSA500 Homework 1: Using OLS Regression to Predict Median House Values in Philadelphia</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Ling Chen, Hang Zhao, Jiahang Li </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">October 16, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<section id="introduction" class="level1">
<h1><strong>Introduction</strong></h1>
<p>Philadelphia, renowned for its rich history and pulsating present, is home to a continually evolving real estate environment. However, a study by the Economic League reveals a nuanced picture: the overall proportion of Philadelphia households grappling with housing cost burden experienced a decrease from 29.8% to 26.7% between 2016 and 2021(Economic League, 2023). Nevertheless, this alteration in cost burden manifested divergently across various income brackets. Considering housing is a fundamental human necessity, ensuring affordability is crucial for maintaining well-being and quality of life. Consequently, comprehending the factors that influence housing values is essential for exerting better control over the housing market and making more strategic, informed decisions.</p>
<p>This report aims to explore the relationship between median house values and various neighborhood characteristics within the city of Philadelphia. It is widely understood that property values are influenced by both the conditions of the housing and the economic status of the property owners. By analyzing data at the Census block group level, we aim to comprehend the relationship between median house value and several neighborhood characteristics, including the proportion of residents in the Block Group with at least a bachelor‚Äôs degree, housing vacancy, percentage of housing units that are detached single-family houses, and number of households living poverty.</p>
</section>
<section id="methods" class="level1">
<h1><strong>Methods</strong></h1>
<section id="data-cleaning" class="level2">
<h2 class="anchored" data-anchor-id="data-cleaning"><strong>Data Cleaning</strong></h2>
<p>The data focuses on a variety of demographic variables in the census data, starting with 1,816 census data by census block level. To further refine the dataset, a systematic data cleansing process is employed that ultimately cleans the dataset into 1,720 observations. Firstly, block groups with a population of less than 40, those without any housing units, and those with median house values lower than $10,000 are identified and flagged for further action. Additionally, an outlier block group in North Philadelphia, characterized by an unusually high median house value (over $800,000) and very low median household income (less than $8,000), is isolated. These identified anomalies are either removed from the dataset or corrected as needed, ensuring that the final dataset consists of 1720 clean and validated observations. Comprehensive documentation and quality checks are performed throughout the process to maintain data integrity and transparency.</p>
</section>
<section id="exploratory-analysis" class="level2">
<h2 class="anchored" data-anchor-id="exploratory-analysis"><strong>Exploratory Analysis</strong></h2>
<p>The first step involves importing a dataset from ‚ÄúRegressionData.csv‚Äù into R, examining the distribution of the dependent variable (MEDHVAL) and predictors (PCBACHMORE, NBELPOV100, PCTVACANT, PCTSINGLES) using histograms, and calculating their mean and standard deviation. Additionally, logarithmic transformations are applied to these variables, with a special transformation (log(1 + [VAR])) used for variables with zero values. The histograms of both the original and transformed variables are created to assess normality. Finally, a summary statistics table is constructed to present the mean and standard deviation of each variable.</p>
<p>Understanding the characteristics of the data set and the distribution of the variables facilitates the assessment of linearity and normality. The method involves plotting scatter plots as well as using histograms to examine the distribution of the data. This process helps to determine the applicability of different regression models, as various models have different assumptions, such as the normality of residuals. This comprehensive approach enables a thorough exploration of the dataset‚Äôs characteristics, facilitates data normalization where necessary, and prepares the data for subsequent regression analysis. While it is possible for a non-normally distributed variable to have normally distributed values, it is more likely that if the variable itself is not normally distributed, its residuals will not be normally distributed either. This effort is consistent with the goal of creating interpretable regression models, as normally distributed variables and residuals are easier to interpret and comply with regression assumptions, ultimately improving the reliability and utility of the model for understanding relationships in the data.</p>
<p>The next step is to assess the linearity of the relationships between the dependent variable (MEDHVAL) and each of the predictors (PCBACHMORE, NBELPOV100, PCTVACANT, PCTSINGLES). The methodology involves creating four scatter plots, one for each predictor, to visually examine the patterns and associations between these variables. This process enables a qualitative assessment of whether the relationships appear to be linear or exhibit other types of trends, which is crucial for determining the suitability of a linear regression model for subsequent analysis. The scatter plots provide a visual representation of the data, aiding in the decision-making process regarding the choice of regression techniques and the understanding of how predictors may influence the dependent variable.</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1} * x + Œµ\]</span></p>
<p>The third step is assessing the relationships between predictor variables by calculating Pearson correlations, with a focus on identifying multicollinearity among them. The methodology involves using the cor function in R to compute these correlations, producing a correlation matrix. The process entails examining the values in the correlation matrix to determine if any predictors exhibit strong pairwise correlations, which could indicate multicollinearity. Pearson‚Äôs correlation coefficient is from -1 to 1, where -1 indicates a strong negative linear relationship, 1 indicates a strong positive linear relationship, and 0 implies no linear relationship. Multicollinearity, where predictor variables are highly correlated with each other, can lead to unstable and unreliable regression results. The aim is to decide whether it‚Äôs appropriate to include all four variables as predictors in the regression model based on the observed correlations, ensuring a robust and interpretable model for subsequent analysis.</p>
<p><span class="math display">\[
r = \frac{\sum((X_i - \bar{X}) \cdot (Y_i - \bar{Y}))}{\sqrt{\sum(X_i - \bar{X})^2} \cdot \sqrt{\sum(Y_i - \bar{Y})^2}}
\]</span></p>
<p>Finally, visualizing spatial patterns and relationships within geographic data by creating choropleth maps for five variables. The methodology involves utilizing the R programming language and the sf package for importing and handling shapefile data, and the ggplot2 package for creating the choropleth maps. The process begins with importing the shapefile and then plotting each variable individually with color scales chosen for clarity and consistency. The final step combines all five maps into a single figure for presentation, facilitating a visual exploration of spatial distributions and correlations among these variables, and enhancing the understanding of geographic patterns in the dataset.</p>
</section>
<section id="multiple-regression-analysis" class="level2">
<h2 class="anchored" data-anchor-id="multiple-regression-analysis"><strong>Multiple Regression Analysis</strong></h2>
<p>Ordinary Least Squares (OLS) regression is a statistical technique to determine the relationships between a variable of interest, known as the dependent variable, and one or more independent explanatory variables, often referred to as predictors. It is often used to assess the strength and direction of the correlations between variables, indicating whether it‚Äôs positive, negative, or no correlation. It also evaluates how well the model fits the data, providing goodness of fit information. Each beta coefficient of the predictors demonstrates to what extent the dependent variable will change when one unit changes in one of the predictors, holding all other predictors constant. However, while significant predictor variables indicate a certain relationship, they do not establish causation between variables.</p>
<p>We use regression analysis to determine the correlation between the dependent variable, which is the natural log of median house value, represented as LNMEDHVAL, and the predictors which are a proportion of housing units that are vacant PCTVACANT, percent of housing units that are detached single-family houses PCTSINGLES, proportion of residents in Block Group with at least a bachelor‚Äôs degree PCTBACHMOR, and the natural log of number of households that income below 100% poverty level LNNBELPOV100. Our equation is shown as follows:</p>
<p><span class="math display">\[
LNMEDHVAL = \beta_0 + \beta_1PCTVACANT\ + \beta_2PCTSINGLES + \beta_3PCTBACHMOR + \beta_4LNNBELPOV100 + \epsilon
\]</span></p>
<p>Where <span class="math inline">\(\beta_0\)</span> is the y-intercept, interpreting the value of the dependent variable when the predictors are 0; <span class="math inline">\(\beta_1\)</span>, <span class="math inline">\(\beta_2\)</span>, <span class="math inline">\(\beta_3\)</span>, <span class="math inline">\(\beta_4\)</span> are the slope coefficients of the predictors.</p>
<p>For a linear regression model, for any fixed value of independent variable x, there are parameters <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_i\)</span>, and ùúé, where i = 1 in a simple regression and i&gt;1 in a multiple regression, such that y = <span class="math inline">\(\beta_0\)</span> + <span class="math inline">\(\beta_i\)</span>xi +<span class="math inline">\(\epsilon\)</span>, where <span class="math inline">\(\epsilon\)</span> ~ N(0, <span class="math inline">\(\sigma^2\)</span>). The term <span class="math inline">\(\epsilon\)</span> is known as an error term or residual, and for each observation i, is defined as a vertical deviation (distance) between the observed value of y and the predicted value of y, denoted by ≈∑. In addition, <span class="math inline">\(\epsilon\)</span>~N(0, <span class="math inline">\(\sigma^2\)</span>) means that the error terms have a normal distribution with a mean of 0 and variance <span class="math inline">\(\sigma^2\)</span>. This holds for any given value of x, the average error term will be 0, and a typical deviation from the regression line will be <span class="math inline">\(\sigma^2\)</span> units.</p>
<p>There are several assumptions we have to make prior to the linear regression. 1. Check the linearity of each predictor and the dependent variable by creating scatter plots. If no linearity can be observed from the plots, variable transformation or polynomial regression might be better. 2. Examine the normality of residuals by plotting out the histogram. If the histogram is not normally distributed, log transformation may be used to normalize both the dependent variable and predictor. However, sometimes log transformation is not appropriate, especially when there are high zero inflations. 3. Confirm homoscedasticity, which means that the variance of residuals should be constant throughout the different values of x. 4. Predictors should not be strongly correlated with each other, which is also called to prevent multicollinearity. 5. No fewer than 10 observations per predictor.</p>
<p>Given n observations on y, and k predictors x1 ‚Ä¶ xk, the estimates <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, <span class="math inline">\(\beta_2\)</span>, ‚Ä¶. <span class="math inline">\(\beta_k\)</span> are chosen simultaneously to minimize the expression for the Error Sum of Squares (SSE), given by:</p>
<p><span class="math display">\[
SSE=\sum_{i = 1}^{n}{\epsilon^2}=\sum_{i = 1}^{n}{(y - \hat{y})^2}=\sum_{i = 1}^{n}{(y_i-\hat{\beta_0}-\hat{\beta_1}x_1i-\hat{\beta_2}x_2i-...-\hat{\beta_k}x_ki)^2}
\]</span></p>
<p>where ≈∑ is the predicted y of the model, which equals <span class="math inline">\(\beta_0\)</span>+<span class="math inline">\(\beta_1\)</span><span class="math inline">\(x_1\)</span>+<span class="math inline">\(\beta_2\)</span><span class="math inline">\(x_2\)</span>+‚Ä¶..+<span class="math inline">\(\beta_k\)</span><span class="math inline">\(x_k\)</span>, with the minus sign before it would be demonstrated as the equation in the bracket. SSE represents the sum of squared error, or the sum of squared residuals <span class="math inline">\(\epsilon\)</span>, which is the amount of variability in y that is not explained when accounting for x in the model. There is another term SST, which means the total sum of squares, is demonstrated as the following equation:</p>
<p><span class="math display">\[
SST=\sum_{i = 1}^{n}{(y_i-\bar{y})^2}=\sum_{i = 1}^{n}{(y_i-\frac{\sum_{i = 1}^{n}{y_i}}{n})^2}
\]</span></p>
<p>where <span class="math inline">\(\bar{y}\)</span> here represents the overall mean of y values, therefore SST is interpreted as the squared deviation of that observation from the overall mean of y, and then summing those squared deviations across all observations i, without any regard to the value of x.</p>
<p><span class="math display">\[
\hat{\rho}=r=Corr(x,y)=\frac{\sum_{i = 1}^{n}{(x_i-\bar{x})(y_i-\bar{y})}}{\sqrt{\sum_{i = 1}^{n}{(x_i-\bar{x})^2}}{\sqrt{\sum_{i = 1}^{n}{(y_i-\bar{y})^2}}}}
\]</span></p>
<p>Sample correlation coefficient R is a point estimator of the population correlation <span class="math inline">\(\rho\)</span>.</p>
<p>If we use the formula 1 ‚Äì SSE/SST, we can get the coefficient of determination <span class="math inline">\(R^2\)</span>, which is the proportion of observed variation in the dependent variable y that was explained by the model. Also, it always ranges between 0 and 1.</p>
<p><span class="math display">\[
R^2 = 1-\frac{SSE}{SST}
\]</span></p>
<p>To assess our model, we examine the F-statistic and its corresponding p-value. The F-test, often referred to as the omnibus test, evaluates whether any of the independent variables in the model significantly predict the dependent variable. It tests the null hypothesis that none of the independent variables are significant predictors against the alternative hypothesis that at least one of them is. A model that fails to reject the null hypothesis is typically considered less effective. We then focus on the p-value associated with each independent variable. If the p-value for a specific independent variable is below 0.05, we can reject the null hypothesis, indicating that this particular predictor significantly influences the dependent variable. In this case, our null hypothesis, or H0 is that the coefficient <span class="math inline">\(\beta\)</span> equals zero, and the alternative hypothesis, or Ha states that the coefficient <span class="math inline">\(\beta\)</span> does not equal zero, demonstrating as H0: <span class="math inline">\(\beta\)</span>=0 and Ha: <span class="math inline">\(\beta\)</span>$$0;</p>
</section>
<section id="additional-analyses" class="level2">
<h2 class="anchored" data-anchor-id="additional-analyses"><strong>Additional Analyses</strong></h2>
<p>To further test the relationship between median house values and studied neighborhood characteristics, we also run the stepwise regression. Stepwise regression is a statistical method that allows us to understand the statistical relationship between independent and dependent variables. The process of stepwise regression screens candidate variables and automatically identifies influential variables. In this scenario, stepwise regression is used to examine the statistical relationship between the dependent variable (MEDHVAL), and predictors (PCBACHMORE, NBELPOV100, PCTVACANT, and PCTSINGLES) based on the Akaike Information Criterion (a mathematical method for evaluating how well a model fits the data it was generated from). Specifically, the algorithm adds or removes predictors to see if there is a significant change in the model fit determined by the AIC value and retains all predictors resulting in significant changes. The model with a smaller ACI is usually regarded as a better one. However, there are limitations as well. Firstly, stepwise regression often leads to overfitting. To be more specific, sometimes the dataset does not contain enough data samples to accurately represent all possible input data values, leading to poor generalization to new datasets. Furthermore, rather than relying on professional knowledge, the model relies on an automatic process of selecting predictive variables. Therefore, it may overlook a more comprehensive model.</p>
<p>To test the problem of overfitting, we implement the K-fold cross-validation, a method used for evaluating the model performance. To further explain this, in this scenario(k=5), the sample dataset is randomly divided into five folds for training and validation. During each run, one-fold is selected for validation, and the rest are used for training and further iterations. This process is repeated five times, each with a different fold serving as the validation set and the other four as the training set. After this process, we will get five different performance values for each fold, the average of which serves as a holistic performance metric to determine how generalizable our model is. In this scenario, we will use the root mean squared error (RMSE) as the referencing performance value to evaluate the model‚Äôs performance. The RMSE measures the average magnitude of errors between the predicted and observed values in a dataset. In other words, it tells us the standard deviation of the residuals (prediction errors).</p>
<p>Turning to the discussion of the formula of the RMSE calculation, firstly, we need to get the SSE. In the formula below, Xi stands for the observed values, Xn stands for the corresponding predicted values. The SSE is calculated as:</p>
<p><span class="math display">\[
SSE = \sum_{i = 1}^{n}{(x_i- x_n )^2}
\]</span> We can then get the mean squared error (MSE) by dividing SSE by the number of observations n: <span class="math display">\[
MSE = \frac{\sum_{i = 1}^{n}{(x_i- x_n )^2}}{n}
\]</span></p>
<p>After taking the square root of the MSE, we get the value for RMSE: <span class="math display">\[
RMSE =\sqrt{\frac{\sum_{i = 1}^{n}{(x_i- x_n )^2}}{n}}
\]</span> In this study, we initially conduct cross-validation on the regression model incorporating all four predictors. Subsequently, for comparative purposes, we also perform cross-validation on a model using only PCTBANT(housing vacancy) and MEDHHINC(median household income) as predictors.</p>
</section>
<section id="software" class="level2">
<h2 class="anchored" data-anchor-id="software"><strong>Software</strong></h2>
<p>The software we used is R, a programming language with powerful statistical analysis capabilities.</p>
</section>
</section>
<section id="results" class="level1">
<h1><strong>Results</strong></h1>
<section id="exploratory-results" class="level2">
<h2 class="anchored" data-anchor-id="exploratory-results"><strong>Exploratory Results</strong></h2>
<section id="summary-statistics" class="level3">
<h3 class="anchored" data-anchor-id="summary-statistics">Summary Statistics</h3>
<p>First of all, we import the csv and shp data files. To see the fundamental statistical information of the original data, we perform summary() function to see the mean values, and the sd() function to see the standard deviation of each variable. The results are shown below in the table.</p>
<table class="table">
<colgroup>
<col style="width: 76%">
<col style="width: 11%">
<col style="width: 11%">
</colgroup>
<thead>
<tr class="header">
<th>Variable</th>
<th>Mean</th>
<th>SD</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Dependent Variable</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Median House Value</td>
<td>66287.73</td>
<td>60006.08</td>
</tr>
<tr class="odd">
<td>Predictors</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>N of Households Living in Poverty.</td>
<td>189.7709</td>
<td>164.3185</td>
</tr>
<tr class="odd">
<td>% of Individuals with Bechelor‚Äôs Degrees or Higher</td>
<td>16.08137</td>
<td>17.76956</td>
</tr>
<tr class="even">
<td>% of Vacant Houses</td>
<td>11.28853</td>
<td>9.628472</td>
</tr>
<tr class="odd">
<td>% of Single House Units</td>
<td>9.226473</td>
<td>13.24925</td>
</tr>
</tbody>
</table>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># look at mean values in summary table</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    POLY_ID          AREAKEY                MEDHVAL          PCTBACHMOR    
 Min.   :   1.0   Min.   :421010000000   Min.   :  10000   Min.   : 0.000  
 1st Qu.: 430.8   1st Qu.:421010000000   1st Qu.:  35075   1st Qu.: 4.847  
 Median : 860.5   Median :421010000000   Median :  53250   Median :10.000  
 Mean   : 860.5   Mean   :421010000000   Mean   :  66288   Mean   :16.081  
 3rd Qu.:1290.2   3rd Qu.:421010000000   3rd Qu.:  78625   3rd Qu.:20.074  
 Max.   :1720.0   Max.   :421010000000   Max.   :1000001   Max.   :92.987  
    MEDHHINC        PCTVACANT        PCTSINGLES        NBELPOV100    
 Min.   :  2499   Min.   : 0.000   Min.   :  0.000   Min.   :   0.0  
 1st Qu.: 21060   1st Qu.: 4.372   1st Qu.:  2.110   1st Qu.:  72.0  
 Median : 29719   Median : 9.091   Median :  5.714   Median : 147.0  
 Mean   : 31542   Mean   :11.289   Mean   :  9.226   Mean   : 189.8  
 3rd Qu.: 38750   3rd Qu.:16.282   3rd Qu.: 11.056   3rd Qu.: 257.0  
 Max.   :200001   Max.   :77.119   Max.   :100.000   Max.   :1267.0  </code></pre>
</div>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># print out all the standard deviations</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(data<span class="sc">$</span>MEDHVAL)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 60006.08</code></pre>
</div>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(data<span class="sc">$</span>NBELPOV100)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 164.3185</code></pre>
</div>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(data<span class="sc">$</span>PCTBACHMOR)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 17.76956</code></pre>
</div>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(data<span class="sc">$</span>PCTVACANT)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 9.628472</code></pre>
</div>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(data<span class="sc">$</span>PCTSINGLES)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 13.24925</code></pre>
</div>
</div>
</section>
<section id="histograms-and-log-transformation" class="level3">
<h3 class="anchored" data-anchor-id="histograms-and-log-transformation">Histograms and Log Transformation</h3>
<p>The histograms below illustrate the distribution of the dependent variable and the four predictors, where all of these histograms are positively skewed. Consequently, we have applied Log transformation to the original variables to normalize their distributions. We have added 1 to the log-transformed data to avoid Log(0) which is undefined. Following that, we present new histograms depicting the distribution of the log-transformed variables.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="MUSA500_HW1_PredictHouseValues_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display">
<p><img src="MUSA500_HW1_PredictHouseValues_files/figure-html/unnamed-chunk-4-2.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>From the new histograms, we can see that LNPCTBACHMOR, LNPCTVACANT, LNPCTSINGLES all have zero inflation, which means that there are very high frequency of zero values in the histograms after log transformation. Keeping that in mind, we will only use the log Median House Value presented as LNMEDHVAL (dependent variable), and log Number of Household living in Poverty LNNBELPV100 (one predictor) for the following regression analysis, while keeping the other three variables original.</p>
<p>Other assumptions for linear regression including checking the linear relationship between dependent variable y and each of the predictors x, homoscedasticity of the variance of residuals, independence of observations, and multicollinearity will also be examined in the following section 3.3</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="MUSA500_HW1_PredictHouseValues_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid" width="768"></p>
</div>
<div class="cell-output-display">
<p><img src="MUSA500_HW1_PredictHouseValues_files/figure-html/unnamed-chunk-5-2.png" class="img-fluid" width="768"></p>
</div>
</div>
</section>
<section id="choropleth-maps" class="level3">
<h3 class="anchored" data-anchor-id="choropleth-maps">Choropleth maps</h3>
<p>Choropleth maps of each variable, LNMEDHVAL, LNNBELPOV, PCTVACANT, PCTSINGLES, and PCTBACHMOR are presented below. We used 5 quantile breaks as the map representation method. From the maps, we can see that there are some clear overlaps between LNMEDHVAL map(Figure 1) and PCTBACHMOR map(Figure 5), showing a strong correlation of the predictor % of Bachelor‚Äôs Degree to the dependent variable Median House Value. Whereas the LNNBELPOV and PCTVACANT maps have completely different patterns from the MEDHVAL map, illustrating very weak correlations. PCTSINGLES however, is presenting a partially similar pattern to the MEDHVAL, which may have some extent of correlation to the dependent variable.</p>
<p>Among the predictors, there are no obvious similarities between the maps, while LNNBELPOV does show a little overlap with the PCTVACANT, we do not expect there to be severe multicollinearity between the predictors.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="MUSA500_HW1_PredictHouseValues_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid" width="768"></p>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<p><img src="MUSA500_HW1_PredictHouseValues_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid" width="1536"></p>
</div>
</div>
</section>
<section id="correlation-matrix" class="level3">
<h3 class="anchored" data-anchor-id="correlation-matrix">Correlation Matrix</h3>
<p>The correlation matrix in the graph and table is shown below. It is used to test multicollinearity between the predictors. The table shows that the greatest correlation coefficients between predictors are -0.31, 0.24, and -0.29, which are not strongly correlated. Therefore, no severe multicollinearity between the predictors has been observed, which aligns with the expectations from previous map observations.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="MUSA500_HW1_PredictHouseValues_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid" width="384"></p>
</div>
</div>
<p>Look at multicollinearity (exclude the dependent variable in the correlation matrix table)</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>            LNNBELPOV PCTBACHMOR  PCTVACANT PCTSINGLES
LNNBELPOV   1.0000000 -0.3197668  0.2495470 -0.2905159
PCTBACHMOR -0.3197668  1.0000000 -0.2983580  0.1975461
PCTVACANT   0.2495470 -0.2983580  1.0000000 -0.1513734
PCTSINGLES -0.2905159  0.1975461 -0.1513734  1.0000000</code></pre>
</div>
</div>
</section>
</section>
<section id="regression-results" class="level2">
<h2 class="anchored" data-anchor-id="regression-results"><strong>Regression Results</strong></h2>
<p>In our analysis of median house values in Philadelphia, we used a linear regression model to investigate the relationships between several predictor variables and the natural logarithm of median house values(LNMEDHVAL).</p>
<p>The final equation is as follows:</p>
<p><span class="math display">\[ln(y) = LNMEDHVAL = \beta_{0} + \beta_{1}PCTVACANT + \beta_{2}PCTSINGLES  + \beta_{3}PCTBACHMOR + \beta_{4}LNBELPOV + \epsilon\]</span></p>
<p>From the statistical summary table, there are several key findings. Firstly, the F-statistic is high and the P-value is much smaller than 0.05. Therefore, we can reject the null hypothesis that none of the independent variables in the model is a significant predictor of the dependent variable. Secondly, the coefficients for each predictor variable also provide some insights.</p>
<p>Notably, a higher percentage of vacant housing units(PCTVACANT) is associated with a significant decrease in median house values, indicating the negative impact of housing vacancy on property values. That is to say, a 1% additional proportion of vacant housing units is associated with a $19 decrease in median house values. In addition, a higher number of households with incomes below 100% of the poverty level(LNNBELPOV) is associated with a significant decrease in median house values as well. As the number of households in poverty changes by 1%, the expected value of median house values changes by <span class="math inline">\((1.01^{\beta_1} - 1)*100 = (1.01^{-.079} - 1) * 100 = -0.0786 \%\)</span> Conversely, the percentage of housing units that are detached single-family houses(PCTSINGLES) has a strong positive relationship with house values. 1% additional percentage of housing units that are detached single-family houses is associated with a $3 increase in median house values. Also, a higher proportion of residents with at least a bachelor‚Äôs degree(PCTBACHMOR) exhibits a strong positive relationship with house values, showing that areas with a well-educated population tend to have higher property values. Specifically, the expected change in median house values associated with 1 additional percentage of residents who has at least a bachelor‚Äôs degree is <span class="math inline">\((e^{\beta_1} - 1)*100\% = (e^{.021} - 1) * 100 \% = 2.12 \%\)</span> Finally, the multiple R-square(0.6623) indicates that approximately 66.23% of the variance in median house values can be explained by the model. The adjusted R-squared further takes into account the number of predictors in the model, which is 66.15% in this case.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># run the 'lm' function</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>lm1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(LNMEDHVAL <span class="sc">~</span> PCTVACANT <span class="sc">+</span> PCTSINGLES <span class="sc">+</span> PCTBACHMOR <span class="sc">+</span> LNNBELPOV, </span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>          <span class="at">data=</span>data_cor)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># print out the statistical summary table</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(lm1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = LNMEDHVAL ~ PCTVACANT + PCTSINGLES + PCTBACHMOR + 
    LNNBELPOV, data = data_cor)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.25817 -0.20391  0.03822  0.21743  2.24345 

Coefficients:
              Estimate Std. Error t value             Pr(&gt;|t|)    
(Intercept) 11.1137781  0.0465318 238.843 &lt; 0.0000000000000002 ***
PCTVACANT   -0.0191563  0.0009779 -19.590 &lt; 0.0000000000000002 ***
PCTSINGLES   0.0029770  0.0007032   4.234            0.0000242 ***
PCTBACHMOR   0.0209095  0.0005432  38.494 &lt; 0.0000000000000002 ***
LNNBELPOV   -0.0789035  0.0084567  -9.330 &lt; 0.0000000000000002 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.3665 on 1715 degrees of freedom
Multiple R-squared:  0.6623,    Adjusted R-squared:  0.6615 
F-statistic: 840.9 on 4 and 1715 DF,  p-value: &lt; 0.00000000000000022</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># check the anova result</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(lm1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Response: LNMEDHVAL
             Df  Sum Sq Mean Sq  F value                Pr(&gt;F)    
PCTVACANT     1 180.383 180.383 1343.093 &lt; 0.00000000000000022 ***
PCTSINGLES    1  24.543  24.543  182.741 &lt; 0.00000000000000022 ***
PCTBACHMOR    1 235.111 235.111 1750.586 &lt; 0.00000000000000022 ***
LNNBELPOV     1  11.692  11.692   87.054 &lt; 0.00000000000000022 ***
Residuals  1715 230.332   0.134                                   
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
</section>
<section id="regression-assumption-checks" class="level2">
<h2 class="anchored" data-anchor-id="regression-assumption-checks"><strong>Regression Assumption Checks</strong></h2>
<p>In this section, we‚Äôll be talking about testing model assumptions. Through the exploratory analysis above, we already have a general understanding of the distribution of the variables through histograms. In this part, we will further test whether the assumption of the linear relationship between the dependent variable (LNMEDHVAL) and each predictor is valid.</p>
<section id="model-assumptions-linearity" class="level3">
<h3 class="anchored" data-anchor-id="model-assumptions-linearity">Model Assumptions: Linearity</h3>
<p>As we can see from the scatter plots, none of the relationships between the dependent variable (LNMEDHVAL) and each of the predictors appear to be strictly linear. Except for the relationship between median home value (LNMEDHVAL) and the percentage of residents with at least a bachelor‚Äôs degree (PCTBACHMOR) which seems to be the most linear. The other scatter plots show data points either concentrated in the center or the lower left corner. Thus, with the exception of the relationship between LNMEDHVAL and PCTBACHMOR, the relationships between the dependent variable and most of the predictors deviate significantly from the assumption of strict linearity.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="MUSA500_HW1_PredictHouseValues_files/figure-html/unnamed-chunk-17-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="normality-of-residuals" class="level3">
<h3 class="anchored" data-anchor-id="normality-of-residuals">Normality of residuals</h3>
<p>The normality of residuals is important for point estimation, confidence intervals, and hypothesis tests only for small samples due to the central limit theorem. In our model, the number of observations reaches more than 1,400. Meanwhile, it‚Äôs easy to notice from the histogram that most of the residuals are clustered around 0 and the trend seems to be normal.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="MUSA500_HW1_PredictHouseValues_files/figure-html/unnamed-chunk-18-1.png" class="img-fluid" width="768"></p>
</div>
</div>
</section>
<section id="additional-checks-homoscedasticity" class="level3">
<h3 class="anchored" data-anchor-id="additional-checks-homoscedasticity">Additional Checks: Homoscedasticity</h3>
<p>Standardized residuals are residuals divided by their standard error. <span class="math display">\[
e_i^* \approx \frac{\epsilon_i}{s} \approx \frac{\epsilon_i}{\sqrt{\frac{SSE}{n-2}}}
\]</span> They are used to compare residuals for different observations to each other. If a particular standardized residual is 2, then the residual itself is 2 (estimated) standard deviations larger than what would be expected from fitting the ‚Äúcorrect‚Äù model.</p>
<p>By examining the ‚ÄòStandardized Residual by Predicted Value‚Äô scatter plot, the goal is to discern the presence of heteroscedasticity ‚Äî a scenario where the variance of residuals differs for various fitted values. A clear pattern or funnel shape in this scatter plot would indicate heteroscedasticity, suggesting systematic under-predictions or over-predictions by the model for certain ranges of fitted values. Upon analysis, the scatter plot demonstrates a relatively consistent spread of residuals across the range of fitted values, pointing towards homoscedasticity.</p>
<p>Additionally, some points lie further from the dense cluster, potentially indicating outliers. These extremely standardized residuals can influence model estimates and might warrant further investigation.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="MUSA500_HW1_PredictHouseValues_files/figure-html/unnamed-chunk-20-1.png" class="img-fluid" width="768"></p>
</div>
</div>
</section>
<section id="spatial-autocorrelation" class="level3">
<h3 class="anchored" data-anchor-id="spatial-autocorrelation">Spatial Autocorrelation</h3>
<p>Observing the maps of the dependent variable and the predictors, there‚Äôs a discernible spatial autocorrelation between the median house values and the percentage of residents holding at least a bachelor‚Äôs degree. Prominent clusters of higher values can be identified in the northwest, northeast, center city, and university city regions of Philadelphia. This suggests that block groups nearby tend to exhibit similar values, challenging the notion that these observations are spatially independent.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="MUSA500_HW1_PredictHouseValues_files/figure-html/unnamed-chunk-21-1.png" class="img-fluid" width="1536"></p>
</div>
</div>
</section>
<section id="standardized-regression-residuals-map" class="level3">
<h3 class="anchored" data-anchor-id="standardized-regression-residuals-map">Standardized regression residuals map</h3>
<p>From the map of the standardized regression residuals, there appear to be clusters of similar color. This suggests that there might be certain areas where the residuals are consistently high or low, which means the model might have systematically overestimated or underestimated the house values. In the map, given the clustering of similar colors in certain regions, there appears to be some degree of positive spatial autocorrelation in the residuals.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="MUSA500_HW1_PredictHouseValues_files/figure-html/unnamed-chunk-22-1.png" class="img-fluid" width="768"></p>
</div>
</div>
</section>
</section>
<section id="additional-models" class="level2">
<h2 class="anchored" data-anchor-id="additional-models"><strong>Additional Models</strong></h2>
<section id="using-stepwise-regression-and-determine-the-best-model" class="level3">
<h3 class="anchored" data-anchor-id="using-stepwise-regression-and-determine-the-best-model">using stepwise regression and determine the best model</h3>
<p>As is depicted in the result of the stepwise model, all 4 predictors in the original model are retained in the final model. To be more specific, compared with other models with some of the variables dropped, the original has the smallest AIC, -3448.16, indicating that the original model does the best prediction.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>best_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(LNMEDHVAL <span class="sc">~</span> PCTVACANT <span class="sc">+</span> PCTSINGLES <span class="sc">+</span> PCTBACHMOR <span class="sc">+</span> LNNBELPOV100, <span class="at">data=</span>data_cor)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>step <span class="ot">&lt;-</span> <span class="fu">stepAIC</span>(best_model, <span class="at">direction=</span><span class="st">"both"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Start:  AIC=-3448.16
LNMEDHVAL ~ PCTVACANT + PCTSINGLES + PCTBACHMOR + LNNBELPOV100

               Df Sum of Sq    RSS     AIC
&lt;none&gt;                      230.33 -3448.2
- PCTSINGLES    1     2.407 232.74 -3432.3
- LNNBELPOV100  1    11.692 242.02 -3365.0
- PCTVACANT     1    51.543 281.87 -3102.8
- PCTBACHMOR    1   199.014 429.35 -2379.0</code></pre>
</div>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># stepwise regression - Analysis of Variance (ANOVA)</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>step<span class="sc">$</span>anova</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Stepwise Model Path 
Analysis of Deviance Table

Initial Model:
LNMEDHVAL ~ PCTVACANT + PCTSINGLES + PCTBACHMOR + LNNBELPOV100

Final Model:
LNMEDHVAL ~ PCTVACANT + PCTSINGLES + PCTBACHMOR + LNNBELPOV100


  Step Df Deviance Resid. Df Resid. Dev       AIC
1                       1715   230.3317 -3448.162</code></pre>
</div>
</div>
</section>
<section id="k-fold-model" class="level3">
<h3 class="anchored" data-anchor-id="k-fold-model">K-fold model</h3>
<p>After performing cross-validation on the models, we obtained the following results: the RMSE for the original regression model stands at 0.366, while the secondary model has an RMSE of 0.443.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>rmse1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.3664306</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>rmse2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.442712</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="discussion-and-limitations" class="level1">
<h1><strong>Discussion and Limitations</strong></h1>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>In summary, we examined the relationship between median house values and several neighborhood characteristics using Philadelphia data at the Census block group level. More specifically, linear regression was done between the dependent variable MEDHVAL (Median House Values) and the predictors PCTBACHMOR (Percentage of Bachelor‚Äôs Degree or Higher), NBELPOV100 (Number of Households living in Poverty), PCTVACANT (Percentage of Vacant Houses), and PCTSINGLES (Percentage of Single House Units). Because all variables are positively skewed, we applied log transformation to each variable, and decided to use log MEDHVAL, and log NBELPOV100 in our model, because although all variables are normalized after log transformation, the other three variables all have zero inflations, while NBELPOV100 and MEDHVAL do not have/have negligible frequency of zero values.</p>
<p>After that, regression assumptions were checked: multicollinearity, linear relationship between dependent variables and predictors, homoscedasticity of variance of residuals, and normality of residuals, where all the assumption requirements are successfully met in this model. The result of linear regression presented that all four predictors are significant with p values far less than 0.05, which means that the null hypothesis of the beta coefficient equal to zero can be rejected, and all four predictors are significantly correlated with the dependent variable LNMEDHVAL. Within those, predictor PCTBACHMOR demonstrates the most significant association with the LNMEDHVAL.</p>
<p>Finally, we applied stepwise regression and k-fold cross-validation to further validate our result. Overall, all four predictors are kept in the stepwise regression, and the rmse value (root mean squared error) in our model is significantly lower than the rmse value in the model that only has PCTVACANT and MEDHHINC (Median household income) as predictors. Therefore, it validates that our model performs better.</p>
</section>
<section id="model-quality" class="level2">
<h2 class="anchored" data-anchor-id="model-quality">Model Quality</h2>
<p>The conducted analysis indicates that the regression model is a good one overall. Firstly, based on the regression results, the high F-statistic means that we can reject the null hypothesis that none of the independent variables in the model is a significant predictor of the dependent variable. Also, the multiple R-square (0.6623) indicates that approximately 66.23% of the variance in median house values can be explained by the model. The result of the stepwise regression further supports the strength of the model. Specifically, all predictors in the original model are retained in the final model, which means that the original model is the best. All predictors have a statistically strong relationship with the dependent variable. Moreover, a cross-validation comparison reveals the original model‚Äôs superiority. When considering all four variables, the model achieves a lower RMSE of 0.366, while a model based solely on ‚Äòhousing vacancy‚Äô and ‚Äòmedian household income‚Äô has a higher RMSE of 0.443. This lower RMSE implies that the comprehensive model offers better predictive accuracy and alignment with actual values.</p>
<p>This analysis confirms a robust relationship between median household value and factors including residents‚Äô educational level, housing vacancy, the proportion of detached single-family houses, and number of households living in poverty. Specifically, housing vacancy rates and the percentage of detached single-family homes can be seen as reflections of housing quality and price trends. Meanwhile, poverty and education levels provide insight into the economic standing and purchasing power of potential homeowners.</p>
<p>While the current model is insightful, there is potential to enhance the model‚Äôs comprehensiveness by introducing additional variables. For instance, the age of the housing stock exerts a profound influence on housing prices, and the number of bedrooms within a property can also significantly impact its market value. These considerations underscore the opportunity for enriching the model with a more comprehensive set of predictors.</p>
</section>
<section id="limitations" class="level2">
<h2 class="anchored" data-anchor-id="limitations">Limitations</h2>
<p>In terms of the model‚Äôs limitations, it‚Äôs important to note that the relationships between predictors and the dependent variable are not strictly linear. Only the relationship between PCTBACHMOR and MEDHVAL appears to be relatively linear. This violation of linearity assumptions could potentially introduce bias into parameter estimates and result in inaccurate outcomes. While attempts were made to address this by transforming some predictors using logarithmic transformations, certain predictors still contained significant zero values, so they were retained in their original form. Additionally, some predictors are interrelated with each other; for instance, the percentage of residents with at least a bachelor‚Äôs degree is negatively correlated with the poverty status. Furthermore, an examination of the residuals map reveals the presence of spatial autocorrelation, which could lead to inefficient parameter estimates. As such, addressing nonlinear relationships, correlated observations, and spatial autocorrelation is crucial when modeling this data.</p>
<p>Also, for the NBELPOV100 variable, we use raw numbers instead of percentages, which might make it difficult to compare across different geographical regions or time periods, as it lacks contexts or normalization. This may further lead to misleading interpretations of the predictor‚Äôs effect. On the other hand, it‚Äôs also challenging to explain the practical implications of changes in the number of households in poverty without considering the total population or percentage of poverty.</p>
</section>
<section id="ridge-and-lasso-regression" class="level2">
<h2 class="anchored" data-anchor-id="ridge-and-lasso-regression">Ridge and LASSO Regression</h2>
<p>Ridge and LASSO regression are alternative regression techniques similar to each other that allow for multicollinearity, allow for a larger number of predictors than observations, and deal with overfitting by shrinking the coefficient of variables to 0. However, both Ridge and LASSO regression will result in biased predicted values while the variance becomes lower, and they will increase the complexity of the model and the way of interpretation. The problem of Ridge regression is that all k predictors will be included, that is, it cannot perform variable selection. LASSO regression on the other hand can do variable selection but still has other limitations. Normally, ridge/LASSO regression will be applied when there is severe multicollinearity, few observations relative to the number of predictors, or we would like a better fit for unseen data than with OLS regression. In this case, as our model does not have the problem of multicollinearity and our number of observations is larger than the number of predictors, we assume that it is unnecessary to perform those two regression methods.</p>
</section>
</section>
<section id="references" class="level1">
<h1><strong>References</strong></h1>
<p>Economy League. (2023). Philadelphia‚Äôs Housing Cost-burden: A Pre- and Post-Pandemic Comparison. https://www.economyleague.org/resources/philadelphias-housing-cost-burden-pre-and-post-pandemic-comparison</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">¬© CC-Hang Zhao, 2023</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">This page is built with ‚ù§Ô∏è and <a href="https://quarto.org/">Quarto</a>.</div>
  </div>
</footer>



</body></html>